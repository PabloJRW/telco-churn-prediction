{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47b13331-6ee8-48a8-a5df-eb9af62e0111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95645dec-ac6e-41bc-8fb2-5894ec48ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets Paths\n",
    "X_train_resampled_path = os.path.join('..','datasets','prepared_data','X_train_resampled.csv') # SMOTE applied  \n",
    "X_train_reduced_path = os.path.join('..','datasets','prepared_data','X_train_reduced.csv')     # PCA applied (It was resampled before)\n",
    "X_test_path = os.path.join('..','datasets','prepared_data','X_test_transformed.csv') \n",
    "X_test_reduced_path = os.path.join('..','datasets','prepared_data','X_test_reduced.csv') \n",
    "y_train_path = os.path.join('..','datasets','prepared_data','y_train_resampled.csv') # SMOTE applied\n",
    "y_test_path = os.path.join('..','datasets','prepared_data','y_test.csv')\n",
    "\n",
    "# Load Datasets\n",
    "X_train_resampled = pd.read_csv(X_train_resampled_path) # PCA Reduced Dataset\n",
    "X_train_reduced = pd.read_csv(X_train_reduced_path)     # PCA applied (It was resampled before)\n",
    "X_test_reduced = pd.read_csv(X_test_reduced_path)               # PCA\n",
    "X_test = pd.read_csv(X_test_path)             \n",
    "y_train = pd.read_csv(y_train_path)\n",
    "y_test = pd.read_csv(y_test_path)\n",
    "\n",
    "# Ensure y are 1D arrays\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8968ef-b38d-44de-84d3-40daa2580ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "Best parameters: {'C': 0.1, 'l1_ratio': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best score: 0.8166709849495142\n"
     ]
    }
   ],
   "source": [
    "# Define the base model\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],  # Regularization types\n",
    "    'C': [0.01, 0.1, 1, 10, 100],                 # Inverse of regularization strength\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs'],     # Optimization algorithms\n",
    "    'l1_ratio': [0.1, 0.5, 0.9]                   # Only used with 'elasticnet' penalty\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall',   # Use 'f1' or 'roc_auc' depending on the problem\n",
    "    cv=5,               # Number of cross-validation folds\n",
    "    n_jobs=-1,          # Use all available CPU cores\n",
    "    verbose=1           # Display progress details\n",
    ")\n",
    "\n",
    "# Run GridSearchCV\n",
    "grid_search.fit(X_train_resampled, y_train)\n",
    "\n",
    "# Display the best hyperparameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f612d535-b331-4c28-9e3f-9550d35a9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd72d0b8-25a7-4370-979a-d3b640c419f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80      1552\n",
      "           1       0.50      0.77      0.61       561\n",
      "\n",
      "    accuracy                           0.73      2113\n",
      "   macro avg       0.70      0.75      0.70      2113\n",
      "weighted avg       0.79      0.73      0.75      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee1e1b5-0c20-4ef3-bf42-131bafb7a84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\trained_models\\\\logistic_regression.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model\n",
    "dump(best_model, os.path.join('..','trained_models','logistic_regression.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a91dd0-eb0d-48c9-a18b-2b411539660b",
   "metadata": {},
   "source": [
    "## With Reduced Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2333785c-1e83-4aad-853f-f534da55c8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "Best parameters: {'C': 0.01, 'l1_ratio': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best score: 0.8128051057344254\n"
     ]
    }
   ],
   "source": [
    "# Define the base model\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=500)\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],  # Regularization types\n",
    "    'C': [0.01, 0.1, 1, 10, 100],                 # Inverse of regularization strength\n",
    "    'solver': ['liblinear', 'saga', 'lbfgs'],     # Optimization algorithms\n",
    "    'l1_ratio': [0.1, 0.5, 0.9]                   # Only used with 'elasticnet' penalty\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall',   # Use 'f1' or 'roc_auc' depending on the problem\n",
    "    cv=5,               # Number of cross-validation folds\n",
    "    n_jobs=-1,          # Use all available CPU cores\n",
    "    verbose=1           # Display progress details\n",
    ")\n",
    "\n",
    "# Run GridSearchCV\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Display the best hyperparameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "# Get the best model\n",
    "best_model_w_reduced = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08a3aae8-09ca-4303-a9f3-1aa2c9c5f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = best_model_w_reduced.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b27b46-7896-4de4-9011-36feb386616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80      1552\n",
      "           1       0.50      0.77      0.61       561\n",
      "\n",
      "    accuracy                           0.74      2113\n",
      "   macro avg       0.70      0.75      0.70      2113\n",
      "weighted avg       0.79      0.74      0.75      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
